# :pushpin: 백엔드 개발자가 반드시 알아야 할 실무 지식 (최범균 저)


## :seedling: 2장. 느려진 서비스, 어디부터 봐야할까?

### 처리량과 응답 시간
사용자는 무언가를 실행할 때 동작하기까지 걸린 시간으로 성능을 판단하지만 실제로는 다양한 지표가 성능과 관련되어 있다.
네트워크 속도, 디스크 속도, 메모리 크기, 디바이스(스마트폰)의 CPU 속도 등이 여기에 해당한다.
이런 다양한 지표 중에서 서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 `응답 시간` 과 `처리량`을 들 수 있다


#### 응답 시간
- 응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미
- API를 호출하고 전체 JSON 응답을 받을 때까지 소요된 시간이 바로 응답 시간이다.
- 클라이언트(앱이나 브라우저)가 서버로 요청을 보내는 과정은 크게 2단계로 이루어진다.
  - 서버에 연결: TCP를 이용해서 서버에 연결한다.
  - 데이터 전송: 정해진 규칙(프로토콜)에 따라 데이터를 서버에 전송한다.
- 서버는 로직을 실행한 다음에 응답 데이털르 클라이언트에 전송한다.
- 응답 시간은 0.025초처럼 1초보다 짧을 때가 많다. 그래서 성능 측정을 위해 응답 시간을 잴때는 1/1000 초인 밀리초 단위를 사용한다.
- 밀리초를 표현할 때는 10ms처럼 'ms'를 뒤에 붙인다.
- 응답 시간은 API 요청 전송 시간, 서버의 처리 시간, API 응답 전송 시간으로 나뉜다.
  - 서버 개발자는 주로 서버의 처리 시간을 확인한다. 서버 처리 시간은 다음과 같은 요소를 포함한다.
  - 로직 수행 (if, for 등)
  - DB 연동 (SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성 (전송)
- 이중에서도 DB 연동과 외부 API 연동이 큰 비중을 차지한다. 아래는 한 서비스에서 실제 한 요청의 처리 시간을 측정한 결과다.
  - 전체 처리 시간: 348ms
  - API 연동 1 (외부 네트워크에 존재하는 API 호출): 186ms (53%)
  - API 연동 2 (내부 네트워크에 존재하는 API 호출): 44ms (13%)
  - DB 연동 (SQL 실행 6회): 101ms (29%)
  - 로직 수행: 17ms (5%)
- API 연동 2번만으로 전체 처리 시간의 66%나 차지한다. DB 연동도 29%를 차지한다.
- 이러한 이유로 응답 시간을 줄일 때 DB 연동과 API 연동 시간에 집중한다.


#### 처리량
- 처리량은 단위 시간당 시스템이 처리하는 작업량을 의미
- 흔히 `TPS`나 `RPS`로 처리량을 나타낸다.
- TPS는 초당 트랜잭션 수를 의미하는 transaction per second의 약자이다.
- RPS는 초당 요청 수를 의미하는 request per second의 약자이다.
- 최대 TPS는 시스템이 처리할 수 있는 최대 요청 수를 의미한다.
  - 최대 TPS가 5인 서버에 동시에 7개의 요청이 들어오면 이 중 5개만 바로 처리할 수 있다.
  - 나머지 2개는 먼저 실행된 5개의 요청이 끝난 후에야 처리할 수 있다.
- 응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 방법을 고려해야한다.
  - 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
  - 처리 시간 자체를 줄여 대기 시간 줄이기
- 위 두 방법을 적용하면 TPS를 높일 수 있다.
- TPS를 확인하는 가장 간단한 방법은 모니터링 시스템을 활용하는 것이다.
- 스카우터, 핀포인트, 뉴렐릭 같은 도구를 사용하면 실시간 TPS뿐 아니라 과거 특정 시점의 TPS도 확인할 수 있다.


### 서버 성능 개선 기초
- 서비스 초기에는 성능 문제가 잘 발생하지 않음. 사용자 수, 트래픽, 데이터베이스 크기 등이 모두 작기 때문
- 성능 문제는 사용자가 늘면서 점차 나타난다.
- 이때 나타나는 전형적인 증상은 다음과 같다.
  - 순간적으로 모든 사용자 요청에 대한 응답 시간이 심각하게 느려짐. 10초 이상 걸리는 요청이 늘어나고 다수의 요청에서 연결 시간 초과와 같은 오류가 발생
  - 서버를 재시작하면 잠시 괜찮다가 다시 응답 시간이 느려지는 현상이 반복됨
  - 트래픽이 줄어들때까지 심각한 상황이 계속됨
- 트래픽이 증가하면서 성능 문제가 발생하는 주된 이유는 시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문
- 성능 문제는 주로 DB나 외부 API를 연동하는 과정에서 발생한다. 

### 수직 확장과 수평 확장
- 수직 확장 (scale-up)
  - 수직 확장은 CPU, 메모리, 디스크 등의 자원을 증가시키는 것
  - 더 빠른 CPU로 바꾸거나 CPU 코어 수를 늘리고 메모리를 확장하고 디스크를 SSD로 바꾸는 것으로 성능이 개선될 수 있
- 수평 확장 (scale-out)
  - 트래픽이 증가하면 서버를 추가로 투입해 서버를 늘리는 방법을 수평 확장이라고 한다.

#### 로드밸런서
- 서버가 두 대 이상이면 로드 밸런서(load balancer)가 필요하다.
- 로드 밸런서는 사용자 트래픽을 각 서버에 골고루 분배해서 한 서버에 사용자 트래픽이 몰리지 않도록 함
- 이를 통해 전체 서버 자원을 효율적으로 활용할 수 있음
- 로드 밸런서가 트래픽을 알맞게 분산시키기 위해 사용하는 방식은 정적인 방식과 동적인 방식으로 나뉨
  - 정적인 방식의 대표적인 예: 라운드 로빈, IP 해시 방식
    - 라운드 로빈 방식: 클라이언트의 요청을 각 서버에 순차적으로 분배하는 방식
    - IP 해시 방식: 클라이언트의 IP주소를 해시한 값을 기반으로 요청을 전달할 서버를 결정함. IP 해시값은 동일하기 때문에 동일한 클라이언트는 항상 같은 서버로 연결된다.
  - 동적인 방식: 서버의 현재 상태에 따라 트래픽을 분산하는 방식으로 트래픽이 적은 서버에 요청을 보내는 형태로 동작함

#### 주의점
- DB에 문제가 있는 상황에서 DB를 사용하는 서버를 추가로 더 늘리면 DB에 가해지는 부하가 더 커지고 성능 문제는 더 악화된다.
- 실제 병목 지점이 어디인지 파악하는 것이 중요하다.

### DB 커넥션 풀
- DB를 사용하려면 다음 3단계를 거친다.
1. DB에 연결한다.
2. 쿼리를 실행한다.
3. 사용이 끝나면 연결을 종료한다.

- 서버와 DB는 네트워크 통신을 통해 연결된다. 매 요청마다 DB를 연결하고 종료하면 트래픽이 증가할때 급격하게 처리량이 떨어진다.
- 이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다.
  - DB 커넥션 풀은 DB에 연결된 커넥션을 미리 생성해서 보관한다. 그리고 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고 작업이 끝나면 다시 풀에 반환한다.
  - 커넥션 풀을 사용하면 이미 연결된 커넥션을 재사용하기 때문에 응답 시간이 줄어드는 장점이 있음
  - 많이 사용하는 프레임워크나 언어도 DB 커넥션 풀을 지원한다.
    - 스프링 부트는 HikariCP를 커넥션 풀로 사용
    - Go 언어는 자체적으로 DB 커넥션 풀을 지원
- 커넥션 풀은 다양한 설정을 제공한다.
  - 커넥션 풀 크기 (최소 크기, 최대 크기)
  - 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기 시간
  - 커넥션의 유지 시간 (최대 유휴 시간, 최대 유지 시간)

#### 커넥션 풀 크기
- 커넥션 풀 크기: 커넥션 풀에 미리 생성해둘 커넥션 개수를 지정하는 설정 
- 다음과 같은 상황을 가정해보자
  - 커넥션 풀 크기는 5
  - 한 요청에서 쿼리를 실행하는데 1초
  - 데이터 전송 시간은 무시
- 서버에 6개의 요청이 동시에 들어왔을 때 이 중 5개 요청은 풀에서 커넥션을 가져올 수 있다.
- 반면 나머지 1개 요청은 사용할 수 있는 커넥션이 없으므로 다른 요청이 커넥션 사용을 끝내고 풀에 반환할 때까지 기다려야 한다.
- 일반적인 커넥션 풀은 최소 크기와 최대 크기를 설정할 수 있다.
- 커넥션 풀 크기를 늘리면 처리량을 높일 수 있다. 
  - 그러나 DB 서버의 CPU 사용률이 80%에 육박하는 상황에서 커넥션 풀 크기를 늘리면 DB에 가해지는 부하가 더 커져 쿼리 실행 시간이 급격히 증가할 수 있다. 
  - 이러한 상태에서는 커넥션 풀 크기를 유지하거나 줄여서 DB 서버가 포화 상태에 이르지 않도록 해야 한다.

#### 커넥션 대기 시간
- 대부분의 커넥션 풀은 대기 시간을 설정할 수 있다.
- 대기 시간이란 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간을 의미한다.
- 지정된 대기 시간 안에 커넥션을 구하지 못하면 DB 연결 실패 에러가 발생한다.
  - HikariCP의 기본 대기 시간은 30초로 설정되어 있다.
- 대기 시간을 짧게 설정하면 커넥션 풀이 모두 사용 중일때 빠르게 '일시적 오류'와 같은 에러 응답을 사용자에게 보여줄 수 있다.
- 대기 시간때문에 긴 시간동안 무응답 상태로 유지되는 것보다 빠르게 에러를 반환하는 것이 더 낫다.

#### 최대 유휴 시간, 유효성 검사, 최대 유지 시간
- 최대 유휴 시간: 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간을 의미. 최대 유휴 시간을 30분으로 설정하면 30분 이상 사용되지 않은 커넥션은 종료되어 풀에서 제거된다.
- 유효성 검사: 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차
- 최대 유지 시간: 이 값이 4시간으로 설정되어 있다면 커넥션은 생성된 시점부터 최대 4시간까지만 유지된다. 4시간이 지나면 커넥션이 유효하더라도 커넥션을 닫고 풀에서 제거된다.

#### 서버 캐시
- 캐시는 일종의 (키, 값) 쌍을 저장하는 Map과 같은 형태의 데이터 저장소
- 캐시에 데이터를 저장해두면 동일한 데이터를 요청할 때 DB가 아닌 캐시에서 데이터를 읽어와 응답할 수 있다.
- DB뿐만 아니라 복잡한 계산 결과나 외부 API 연동 결과도 캐시에 보관하여 응답 시간을 줄일 수 있다.
  - 캐시를 사용할 때는 캐시 키가 겹치지 않도록 주의해야한다.

#### 적중률과 삭제 규칙
- 캐시가 얼마나 효율적으로 사용되는지는 적중률(hit rate)로 판단할 수 있다.
- 적중률(hit rate) = 캐시에 존재한 건수/캐시에서 조회를 시도한 건수
- 캐시에 보관할 수 있는 데이터에 제한이 있으므로 캐시가 가득 차 있는 상태에서 새로운 데이터를 캐시에 저장하면 기존에 있던 데이터 중 하나를 제거해야한다.
  - LRU(Least Recently Used): 가장 오래전에 사용된 데이터를 제거한다.
  - LFU(Least Frequently Used): 가장 적게 사용된 데이터를 삭제한다.
  - FIFO(First In First Out): 먼저 추가된 데이터를 먼저 삭제한다.

#### 로컬 캐시와 리모트 캐시
- 서버가 사용하는 캐시에는 크게 두 종류가 있음
- *로컬 캐시*: 서버 프로세스와 동일한 메모리를 캐시 저장소로 사용한다.
  - Caffeine(자바), go-cache(Go), node-cache(Node.js) 등
  - 로컬 캐시의 장점은 속도에 있다. 서버 프로세스와 캐시가 동일한 메모리 공간을 사용하므로 캐시 데이터에 빠르게 접근 가능
  - 별도의 외부 연동이 필요하지 않아 구조를 단순하게 유지할 수 있음
  - 로컬 캐시의 단점은 캐시에 저장할 수 있는 데이터 크기에 제한이 있다는 점
  - 서버 프로세스를 재시작하면 메모리에 존재하던 캐시 데잍거ㅏ 모두 삭제되어 일시적으로 캐시 효율(적중률)이 떨어진다.
- *리모트 캐시*: 별도 프로세스를 캐시 저장소로 사용한다.
  - 캐시를 유연하게 확장할 수 있다는 점이 장점
  - 대표적인 리모트 캐시 기술인 레디스(Redis)는 여러 대의 레디스 서버를 이용해서 수평 확장할 수 있는 기능을 제공
  - 또한 서버 프로세스가 재시작되더라도 레디스에 저장된 캐시 데이터는 그대로 유지됨
  - 리모트 캐시의 단점은 속도에 있다.
  
#### 캐시 사전 적재
- 트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려
- 캐시 적중률이 낮아지면 전체 응답 시간이 느려질 뿐만 아니라 DB에 전달되는 부하도 급격히 증가한다.
- 이런 상황을 방지하는 방법 중 하나는 캐시에 데이터를 미리 넣어두는 것이다.

#### 캐시 무효화
- 캐시에 보관된 데이터의 원본이 바뀌면 그에 맞춰 캐시에 보관된 데이터도 함께 변경하거나 삭제해야 한다.
- 원본이 변경됐는데 캐시에 저장된 데이터가 갱신되지 않으면 사용자는 오래된 잘못된 정보를 확인하게 되는 문제가 발생할 수 있다.
- 가격 정보, 게시글 내용처럼 민감한 데이터는 변경되는 즉시 캐시를 무효화해야한다.
- 변경에 민감한 데이터는 로컬 캐시가 아닌 리모트 캐시에 보관해야 한다.
  - 로컬 캐시는 자신의 데이터만 변경하지 다른 서버의 로컬 캐시는 변경하지 않기 때문이다.
- 변경에 민감하지 않고 데이터 크기가 작다면 캐시의 유효 시간을 설정하여 주기적으로 갱신할 수 있다.

#### 가비지 컬렉터와 메모리 사용
- 자바, Go, 파이썬 등의 언어는 가비지 컬렉터를 사용함
- 예를 들어 힙 메모리 사용량이 일정 비율을 초과하면 가비지 컬렉터를 실행하거나 일정 주기로 자동 실행된다.
- 가비지 컬렉터는 개발자가 메모리를 직접 관리해야 하는 부담을 줄여준다. 하지만 가비지 컬렉터는 응답 시간에 영향을 줄 수 있다.

#### 응답 데이터 압축
- 응답 시간에는 데이터 전송 시간이 포함된다. 이 전송 시간은 2가지 요인에 영향을 받는다.
  - 네트워크 속도
  - 전송 데이터 크기
- 웹 서버가 전송하는 응답 데이터 중에서 HTML, CSS, JS, JSON과 같이 텍스트로 구성된 응답은 압축하면 데이터 전송량을 크게 줄일 수 있다.
- 아파치나 Nginx와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.


#### 정적 자원과 브라우저 캐시
- 서버는 2가지 종류의 데이터를 응답한다. 
- 첫번째는 동적 자원이고 두번째는 정적 자원이다.
  - 동적 자원은 브라우저가 요청할 때마다 결과가 바뀌는 데이터로 제품 목록 HTML이나 제품 상세 JSON 응답이 해당한다.
  - 정적 자원은 같은 URL에 대해서 같은 데이터를 응답하는 콘텐츠로 이미지, JS, CSS가 있다.
- 정적 자원은 전체 트래픽에서 상당한 비중을 차지한다. 이미지가 많은 온라인 쇼핑몰 사이트의 첫 페이지는 정적 자원이 전체 데이터의 80%를 차지하기도 한다.
- 클라이언트 캐시
  - HTTP 프로토콜에서는 데이터를 응답할 때 Cache-Control이나 Expires 헤더를 이용해 클라이언트가 응답 데이터를 일정 시간동안 저장해둘 수 있도록 설정할 수 있음
  - `Cache-Control: max-age=60`
- 브라우저 캐시를 활용하면 서버 입장에서도 전송해야 할 트래픽이 줄어들어 그만큼 네트워크 전송 비용을 아낄 수 있다.


#### 정적 자원과 CDN
- 브라우저 캐시는 브라우저 단위로 동작하기 때문에 동시에 많은 사용자가 접속하면 순간적으로 많은 양의 이미지, JS, CSS를 전송