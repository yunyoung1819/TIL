# :pushpin: 백엔드 개발자가 반드시 알아야 할 실무 지식 (최범균 저)


## :seedling: 2장. 느려진 서비스, 어디부터 봐야할까?

### 처리량과 응답 시간
사용자는 무언가를 실행할 때 동작하기까지 걸린 시간으로 성능을 판단하지만 실제로는 다양한 지표가 성능과 관련되어 있다.
네트워크 속도, 디스크 속도, 메모리 크기, 디바이스(스마트폰)의 CPU 속도 등이 여기에 해당한다.
이런 다양한 지표 중에서 서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 `응답 시간` 과 `처리량`을 들 수 있다


#### 응답 시간
- 응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미
- API를 호출하고 전체 JSON 응답을 받을 때까지 소요된 시간이 바로 응답 시간이다.
- 클라이언트(앱이나 브라우저)가 서버로 요청을 보내는 과정은 크게 2단계로 이루어진다.
  - 서버에 연결: TCP를 이용해서 서버에 연결한다.
  - 데이터 전송: 정해진 규칙(프로토콜)에 따라 데이터를 서버에 전송한다.
- 서버는 로직을 실행한 다음에 응답 데이털르 클라이언트에 전송한다.
- 응답 시간은 0.025초처럼 1초보다 짧을 때가 많다. 그래서 성능 측정을 위해 응답 시간을 잴때는 1/1000 초인 밀리초 단위를 사용한다.
- 밀리초를 표현할 때는 10ms처럼 'ms'를 뒤에 붙인다.
- 응답 시간은 API 요청 전송 시간, 서버의 처리 시간, API 응답 전송 시간으로 나뉜다.
  - 서버 개발자는 주로 서버의 처리 시간을 확인한다. 서버 처리 시간은 다음과 같은 요소를 포함한다.
  - 로직 수행 (if, for 등)
  - DB 연동 (SQL 실행)
  - 외부 API 연동
  - 응답 데이터 생성 (전송)
- 이중에서도 DB 연동과 외부 API 연동이 큰 비중을 차지한다. 아래는 한 서비스에서 실제 한 요청의 처리 시간을 측정한 결과다.
  - 전체 처리 시간: 348ms
  - API 연동 1 (외부 네트워크에 존재하는 API 호출): 186ms (53%)
  - API 연동 2 (내부 네트워크에 존재하는 API 호출): 44ms (13%)
  - DB 연동 (SQL 실행 6회): 101ms (29%)
  - 로직 수행: 17ms (5%)
- API 연동 2번만으로 전체 처리 시간의 66%나 차지한다. DB 연동도 29%를 차지한다.
- 이러한 이유로 응답 시간을 줄일 때 DB 연동과 API 연동 시간에 집중한다.


#### 처리량
- 처리량은 단위 시간당 시스템이 처리하는 작업량을 의미
- 흔히 `TPS`나 `RPS`로 처리량을 나타낸다.
- TPS는 초당 트랜잭션 수를 의미하는 transaction per second의 약자이다.
- RPS는 초당 요청 수를 의미하는 request per second의 약자이다.
- 최대 TPS는 시스템이 처리할 수 있는 최대 요청 수를 의미한다.
  - 최대 TPS가 5인 서버에 동시에 7개의 요청이 들어오면 이 중 5개만 바로 처리할 수 있다.
  - 나머지 2개는 먼저 실행된 5개의 요청이 끝난 후에야 처리할 수 있다.
- 응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 방법을 고려해야한다.
  - 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
  - 처리 시간 자체를 줄여 대기 시간 줄이기
- 위 두 방법을 적용하면 TPS를 높일 수 있다.
- TPS를 확인하는 가장 간단한 방법은 모니터링 시스템을 활용하는 것이다.
- 스카우터, 핀포인트, 뉴렐릭 같은 도구를 사용하면 실시간 TPS뿐 아니라 과거 특정 시점의 TPS도 확인할 수 있다.


### 서버 성능 개선 기초
- 서비스 초기에는 성능 문제가 잘 발생하지 않음. 사용자 수, 트래픽, 데이터베이스 크기 등이 모두 작기 때문
- 성능 문제는 사용자가 늘면서 점차 나타난다.
- 이때 나타나는 전형적인 증상은 다음과 같다.
  - 순간적으로 모든 사용자 요청에 대한 응답 시간이 심각하게 느려짐. 10초 이상 걸리는 요청이 늘어나고 다수의 요청에서 연결 시간 초과와 같은 오류가 발생
  - 서버를 재시작하면 잠시 괜찮다가 다시 응답 시간이 느려지는 현상이 반복됨
  - 트래픽이 줄어들때까지 심각한 상황이 계속됨
- 트래픽이 증가하면서 성능 문제가 발생하는 주된 이유는 시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문
- 성능 문제는 주로 DB나 외부 API를 연동하는 과정에서 발생한다. 

### 수직 확장과 수평 확장
- 수직 확장 (scale-up)
  - 수직 확장은 CPU, 메모리, 디스크 등의 자원을 증가시키는 것
  - 더 빠른 CPU로 바꾸거나 CPU 코어 수를 늘리고 메모리를 확장하고 디스크를 SSD로 바꾸는 것으로 성능이 개선될 수 있
- 수평 확장 (scale-out)
  - 트래픽이 증가하면 서버를 추가로 투입해 서버를 늘리는 방법을 수평 확장이라고 한다.

#### 로드밸런서
- 서버가 두 대 이상이면 로드 밸런서(load balancer)가 필요하다.
- 로드 밸런서는 사용자 트래픽을 각 서버에 골고루 분배해서 한 서버에 사용자 트래픽이 몰리지 않도록 함
- 이를 통해 전체 서버 자원을 효율적으로 활용할 수 있음
- 로드 밸런서가 트래픽을 알맞게 분산시키기 위해 사용하는 방식은 정적인 방식과 동적인 방식으로 나뉨
  - 정적인 방식의 대표적인 예: 라운드 로빈, IP 해시 방식
    - 라운드 로빈 방식: 클라이언트의 요청을 각 서버에 순차적으로 분배하는 방식
    - IP 해시 방식: 클라이언트의 IP주소를 해시한 값을 기반으로 요청을 전달할 서버를 결정함. IP 해시값은 동일하기 때문에 동일한 클라이언트는 항상 같은 서버로 연결된다.
  - 동적인 방식: 서버의 현재 상태에 따라 트래픽을 분산하는 방식으로 트래픽이 적은 서버에 요청을 보내는 형태로 동작함

#### 주의점
- DB에 문제가 있는 상황에서 DB를 사용하는 서버를 추가로 더 늘리면 DB에 가해지는 부하가 더 커지고 성능 문제는 더 악화된다.
- 실제 병목 지점이 어디인지 파악하는 것이 중요하다.